In statistics, the standard deviation ..  Logan gives the following example. Furness and Bryant measured the resting metabolic rate for 8 male and 6 female breeding northern fulmars. The table shows the Furness data set. The graph shows the metabolic rate for males and females. By visual inspection, it appears that the variability of the metabolic rate is greater for males than for females. The sample standard deviation of the metabolic rate for the female fulmars is calculated as follows. The formula for the sample standard deviation is : where are the observed values of the sample items, is the mean value of these observations, and N is the number of observations in the sample. In the sample standard deviation formula, for this example, the numerator is the sum of the squared deviation of each individual animal's metabolic rate from the mean metabolic rate. The table below shows the calculation of this sum of squared deviations for the female fulmars. For females, the sum of squared deviations is 886047.09, as shown in the table. The denominator in the sample standard deviation formula is N – 1, where N is the number of animals. In this example, there are N = 6 females, so the denominator is 6 – 1 = 5. The sample standard deviation for the female fulmars is therefore : For the male fulmars, a similar calculation gives a sample standard deviation of 894.37, approximately twice as large as the standard deviation for the females. The graph shows the metabolic rate data, the means . Let X be a random variable with mean value μ: : Here the operator E denotes the average or expected value of X. Then the standard deviation of X is the quantity : is : and where the integrals are definite integrals taken for x ranging over the set of possible values of the random variable&nbsp;X. In the case of a parametric family of distributions, the standard deviation can be expressed in terms of the parameters. For example, in the case of the log-normal distribution with parameters μ and σ2, the standard deviation is :. One can find the standard deviation of an entire population in cases are available for other values of N and for non-normal distributions.. The standard deviation is invariant under changes in location, and scales directly with the scale of the random variable. Thus, for a constant c and random variables X and Y: : : : The standard deviation of the sum of two random variables can be related to their individual standard deviations and the covariance between them: : where and stand for variance and covariance, respectively. The calculation of the sum of squared deviations can be related to moments calculated directly from the data. In the following formula, the letter E is interpreted to mean expected value, i.e., mean. : The sample standard deviation can be computed as: : For a finite population with equal probabilities at all points, we have : This means that the standard deviation is equal to the square root of the difference between the average of the squares of the values and the square of the average value. See computational formula for the variance for proof, and for an analogous result for the sample standard deviation.. A large standard deviation indicates that the data points can spread far from the mean and a small standard deviation indicates that they are clustered closely around the mean. For example, each of the three populations . This is the "main diagonal" going through the origin. If our three given values were all equal, then the standard deviation would be zero and P would lie on L. So it is not unreasonable to assume that the standard deviation is related to the distance of P to L. That is indeed the case. To move orthogonally from L to the point P, one begins at the point: : whose coordinates are the mean of the values we started out with. is on therefore for some . The line is to be orthogonal to the vector from to . Therefore: : A little algebra shows that the distance between P and M , are as follows:. The mean and the standard deviation of a set of data are descriptive statistics usually reported together. In a certain sense, the standard deviation is a "natural" measure of statistical dispersion if the center of the data is measured about the mean. This is because the standard deviation from the mean is smaller than from any other point. The precise statement is the following: suppose x1, ..., xn are real numbers and define the function: : Using calculus or by completing the square, it is possible to show that σ : hence : Resulting in: : It should be emphasized that in order to estimate the standard deviation of the mean it is necessary to know the standard deviation of the entire population beforehand. However, in most applications this parameter is unknown. For example, if a series of 10 measurements of a previously unknown quantity is performed in a laboratory, it is possible to calculate the resulting sample mean and sample standard deviation, but it is impossible to calculate the standard deviation of the mean.. The following two formulas can represent a running . Similarly for sample standard deviation, : In a computer implementation, as the three sj sums become large, we need to consider round-off error, arithmetic overflow, and arithmetic underflow. The method below calculates the running sums method with reduced rounding errors. This is a "one pass" algorithm for calculating variance of n samples without the need to store prior data during the calculation. Applying this method to a time series will result in successive values of standard deviation corresponding to n data points as n grows larger with each new sample, rather than a constant-width sliding window calculation. For k = 1, ..., n: : where A is the mean value. : Note: since or Sample variance: : Population variance: : When the values xi are weighted with unequal weights wi, the power sums s0, s1, s2 are each computed as: : And the standard deviation equations remain unchanged. s0 is now the sum of the weights and not the number of samples N. The incremental method with reduced rounding errors can also be applied, with some additional complexity. A running sum of weights must be computed for each k from 1 to n: : and places where 1/n is used above must be replaced by wi/Wn: : In the final division, : and : or : where n is the total number of elements, and n' is the number of elements with non-zero weights. The above formulas become equal to the simpler formulas given above if weights are taken as equal to one.. The term standard deviation was first used in writing by Karl Pearson in 1894, following his use of it in lectures. This was as a replacement for earlier alternative names for the same idea: for example, Gauss used mean error.